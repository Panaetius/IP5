Hyper Parameters:
NUM_EPOCHS_PER_DECAY = 10.0
LEARNING_RATE_DECAY_FACTOR = 0.5
INITIAL_LEARNING_RATE = 0.0001
WEIGHT_DECAY = INITIAL_LEARNING_RATE * 0.01
batch = 32

-->92.7%, valid: 87.1%, 7:20



Hyper Parameters:
NUM_EPOCHS_PER_DECAY = 30.0
LEARNING_RATE_DECAY_FACTOR = 0.5
INITIAL_LEARNING_RATE = 0.0002
WEIGHT_DECAY = INITIAL_LEARNING_RATE * 0.01
batch = 32

--> 87.1%, valid: 81.5%, 9:14
	2016-10-13 16:52:25.866273: precision @ 1 = 0.815
	precisions: [ 0.94991055  0.93846154  1.          0.99570201  1.          0.85022523
	  0.4143469   0.36503856  0.84304933  0.95483871]
	recalls: [ 0.94652406  0.953125    0.99514563  0.99570201  1.          0.8014862
	  0.83585313  0.35544431  0.61237785  0.96802326]
	f1: [ 0.94821429  0.94573643  0.99756691  0.99570201  1.          0.82513661
	  0.55404438  0.36017755  0.70943396  0.96138578]



Hyper Parameters:
NUM_EPOCHS_PER_DECAY = 30.0
LEARNING_RATE_DECAY_FACTOR = 0.5
INITIAL_LEARNING_RATE = 0.00007
WEIGHT_DECAY = 0.0000007
batch = 32

--> 94.1%, 4:59
	2016-10-13 21:49:58.973936: precision @ 1 = 0.898
	precisions: [ 0.97674419  0.93230769  1.          1.          1.          0.93806306
	  0.7642015   0.75578406  0.767713    0.97279885]
	recalls: [ 0.975       0.95283019  1.          0.98171589  1.          0.85086823
	  0.92959583  0.68933177  0.76021314  0.98051948]
	f1: [ 0.97587131  0.94245723  1.          0.9907736   1.          0.89234065
	  0.83882353  0.72103004  0.76394467  0.97664391]
